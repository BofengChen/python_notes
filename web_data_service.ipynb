{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T08:07:40.868644Z",
     "start_time": "2020-01-08T08:07:40.758214Z"
    }
   },
   "source": [
    "本章节主要介绍获取网上数据相关的模块和内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:14:17.371974Z",
     "start_time": "2020-01-15T11:14:16.053136Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:04:58.871063Z",
     "start_time": "2020-01-08T13:04:58.867072Z"
    }
   },
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:04:59.946911Z",
     "start_time": "2020-01-08T13:04:59.937931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "# 按照标准的缩进格式的结构输出\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:00.133816Z",
     "start_time": "2020-01-08T13:05:00.128829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "body\n"
     ]
    }
   ],
   "source": [
    "# Tag\n",
    "tag = soup.body\n",
    "print (type(tag))\n",
    "# Name:每个tag都有自己的名字,通过 .name 来获取\n",
    "print (tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes:一个tag可能有很多个属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:00.552417Z",
     "start_time": "2020-01-08T13:05:00.525282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title']\n",
      "{'class': ['title']}\n",
      "['body', 'strikeout']\n"
     ]
    }
   ],
   "source": [
    "# tag 有一个 “class” 的属性,值为 “boldest” . tag的属性的操作方法与字典相同.\n",
    "tag_p = tag.p\n",
    "print (tag_p['class'])\n",
    "\n",
    "#也可以直接”点”取属性, 比如: .attrs\n",
    "print (tag_p.attrs)\n",
    "\n",
    "#多值属性：最常见的多值的属性是 class (一个tag可以有多个CSS的class). 在Beautiful Soup中多值属性的返回类型是list。\n",
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>')\n",
    "print (css_soup.p['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:00.786674Z",
     "start_time": "2020-01-08T13:05:00.756752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p \n",
      " {'class': ['my', 'id']} \n",
      " ['my', 'id'] \n",
      " ss \n",
      " {'id': 'my id'}\n"
     ]
    }
   ],
   "source": [
    "id_soup = BeautifulSoup('<p  class=\"my id\">ss</p>')\n",
    "id_soup_1 = BeautifulSoup('<p  id=\"my id\">ss</p>')\n",
    "print (id_soup.p.name,'\\n',\n",
    "       id_soup.p.attrs,'\\n',\n",
    "       id_soup.p['class'],'\\n',\n",
    "       id_soup.p.string,'\\n',\n",
    "       id_soup_1.p.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:00.975010Z",
     "start_time": "2020-01-08T13:05:00.946151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely bold\n",
      "<class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "# 可以遍历的字符串\n",
    "soup = BeautifulSoup('<b class=\"boldest\">Extremely bold</b>')\n",
    "tag_e = soup.b\n",
    "print (tag_e.string)\n",
    "print (type(tag_e.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个 NavigableString 字符串与Python中的Unicode字符串相同,并且还支持包含在 遍历文档树 和 搜索文档树 中的一些特性. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:01.294306Z",
     "start_time": "2020-01-08T13:05:01.282306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b class=\"boldest\">today is not a good day</b>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法\n",
    "tag_e.string.replace_with('today is not a good day')\n",
    "tag_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注释及特殊字符串**\n",
    "\n",
    "Tag , NavigableString , BeautifulSoup 几乎覆盖了html和xml中的所有内容,但是还有一些特殊对象.容易让人担心的内容是文档的注释部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:01.663728Z",
     "start_time": "2020-01-08T13:05:01.654716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Comment'>\n",
      "Hey, buddy. Want to buy a used parser?\n",
      "<b>\n",
      " <!--Hey, buddy. Want to buy a used parser?-->\n",
      "</b>\n"
     ]
    }
   ],
   "source": [
    "markup = \"<b><!--Hey, buddy. Want to buy a used parser?--></b>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "comment = soup.b.string\n",
    "print( type(comment))\n",
    "print (comment)\n",
    "print (soup.b.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:01.851472Z",
     "start_time": "2020-01-08T13:05:01.845498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>The Dormouse's story</title></head>\n",
      "<title>The Dormouse's story</title>\n",
      "<b>The Dormouse's story</b>\n",
      "<b>The Dormouse's story</b>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc)\n",
    "# print (soup.prettify())\n",
    "# tag的名字：操作文档树最简单的方法就是告诉它你想获取的tag的name.如果想获取 <head> 标签,只要用 soup.head \n",
    "print (soup.head)\n",
    "\n",
    "print (soup.title)\n",
    "\n",
    "#可以在文档树的tag中多次调用这个方法\n",
    "print (soup.body.b)\n",
    "print (soup.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果来看，似乎可以直接从根节点访问嵌套tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:02.509925Z",
     "start_time": "2020-01-08T13:05:02.502979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "# 通过点取属性的方式只能获得当前名字的第一个tag\n",
    "print (soup.a)\n",
    "\n",
    "# 如果想要得到所有的<a>标签,或是通过名字得到比一个tag更多的内容的时候,就需要用到 Searching the tree 中描述的方法,比如: find_all()\n",
    "print (soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contents 和 children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tag的 `.contents` 属性可以将tag的子节点以列表的方式输出;\n",
    "* 字符串没有 `.contents` 属性,因为字符串没有子节点;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T13:05:04.134597Z",
     "start_time": "2020-01-08T13:05:04.127614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>The Dormouse's story</title></head>\n",
      "<title>The Dormouse's story</title>\n",
      "[\"The Dormouse's story\"]\n",
      "--------------------\n",
      "\n",
      "\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head_tag = soup.head\n",
    "print (head_tag)\n",
    "\n",
    "title_tag = head_tag.contents[0]\n",
    "print (title_tag)\n",
    "print( title_tag.contents)\n",
    "print ('--------------------')\n",
    "for i in soup.body.contents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T08:27:26.305760Z",
     "start_time": "2020-01-08T08:27:26.298743Z"
    }
   },
   "source": [
    "* 通过tag的 `.children` 生成器,可以对tag的子节点进行循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T08:28:34.346793Z",
     "start_time": "2020-01-08T08:28:34.341809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for child in soup.body.children:\n",
    "    print (child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取网络数据的自定义类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:14:05.986091Z",
     "start_time": "2020-01-15T11:14:05.981105Z"
    }
   },
   "outputs": [],
   "source": [
    "'''发送连接网页的请求'''\n",
    "\n",
    "class web_data(object):\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        \n",
    "    def get_soup(self):\n",
    "        response = urllib.request.urlopen(self.url)\n",
    "        html = response.read()\n",
    "        soup = BeautifulSoup(html, \"html.parser\", from_encoding='utf-8')\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取百度地图相关API的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T02:28:22.210296Z",
     "start_time": "2020-01-09T02:28:22.052566Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class baiduLbsAPI(object):\n",
    "    \"\"\"将和百度地图api相关的服务集成在一起\"\"\"\n",
    "    def __init__(self,basic_dict):\n",
    "        self.ak = basic_dict.get('ak','joEZrGxLI7hH0Bggf7rVBUPwB9hgooyx')\n",
    "        self.outPut_type = basic_dict.get('output_type','json')\n",
    "        self.getAdress_api = 'http://api.map.baidu.com/geocoder/v2/?output={0}&ak={1}'.format(self.outPut_type,self.ak)\n",
    "        \n",
    "    def getGps(self,address):\n",
    "        \"\"\"\n",
    "        服务文档：http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding\n",
    "        功能介绍：\n",
    "        用户可通过该功能，将结构化地址（省/市/区/街道/门牌号）解析为对应的位置坐标。\n",
    "        \"\"\"\n",
    "        api = '{0}&address={1}'.format(self.getAdress_api,address)\n",
    "        if self.outPut_type == 'json':\n",
    "            info_dict = requests.get(api).json()\n",
    "        else:\n",
    "            info_dict = {}\n",
    "            print('please add this part by yourself.')\n",
    "            \n",
    "        print(api,'\\n',info_dict)\n",
    "        if info_dict is not None:\n",
    "            result = info_dict['result']\n",
    "            precise,confidence,comprehension,level = result['precise'],result['confidence'],result['comprehension'],result['level']\n",
    "            lng,lat = result['location']['lng'],result['location']['lat']\n",
    "            return lat,lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T02:28:23.598464Z",
     "start_time": "2020-01-09T02:28:23.532608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.map.baidu.com/geocoder/v2/?output=json&ak=joEZrGxLI7hH0Bggf7rVBUPwB9hgooyx&address=上海市杨浦区吉浦路3号 \n",
      " {'status': 0, 'result': {'location': {'lng': 121.49789529042646, 'lat': 31.30492357706552}, 'precise': 1, 'confidence': 80, 'comprehension': 100, 'level': '门址'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31.30492357706552, 121.49789529042646)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例\n",
    "basic_dict = {'ak':'joEZrGxLI7hH0Bggf7rVBUPwB9hgooyx'}\n",
    "bd = baiduLbsAPI(basic_dict=basic_dict)\n",
    "bd.getGps(address='上海市杨浦区吉浦路3号')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取google全球办公地点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://about.google/intl/en/locations/?region=north-america"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:14:09.367607Z",
     "start_time": "2020-01-15T11:14:09.357664Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_officeAddress_of_region(region):\n",
    "    company_address_dict = defaultdict(list)\n",
    "    \n",
    "    web=web_data(url='https://about.google/intl/en/locations/?region={}'.format(region[0]))\n",
    "    soup=web.get_soup()\n",
    "    for tag in soup.body.main.section.div.find('div',attrs={'class':\"offices-list-container\" }).find_all('ul'):\n",
    "        for sub_tag in tag.find_all('li',attrs={'data-ng-show':\"'{}' === locationsCtrl.selectedRegion\".format(region)}):\n",
    "            office = sub_tag.h2.string.strip()\n",
    "            address = sub_tag.find('div',attrs={'class':\"office-address\", 'itemprop':\"address\"}).string.strip().replace('\\n',' ') \n",
    "            \n",
    "            phone_tag = sub_tag.find('div',attrs={'class':\"office-phone-number\"})\n",
    "            phone = phone_tag.span.string.strip() if phone_tag else None\n",
    "            \n",
    "            direction_tag = sub_tag.find('div',attrs={'class':\"directions\"}).a.attrs['href']\n",
    "            lat,lon = (float(_) for _ in direction_tag.split('/')[-1].split('?')[0].split(','))\n",
    "            for col in ['office','address','phone','lon','lat','region']:\n",
    "                company_address_dict[col].append(eval(col))\n",
    "                \n",
    "            address_df = pd.DataFrame(company_address_dict) \n",
    "    return address_df\n",
    "\n",
    "def get_addressOfGoogle():\n",
    "    region_list=['north-america','latin-america','europe','asia-pacific','africa-middle-east']\n",
    "    df_list = []\n",
    "    for _ in region_list:\n",
    "        df = get_officeAddress_of_region(region=_)\n",
    "        df_list.append(df)\n",
    "    googleOfficeAddress = pd.concat(df_list,axis=0).reset_index(drop=True)\n",
    "    return googleOfficeAddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:14:30.259328Z",
     "start_time": "2020-01-15T11:14:19.332924Z"
    }
   },
   "outputs": [],
   "source": [
    "get_addressOfGoogle().to_csv('addressOfGoogle.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
